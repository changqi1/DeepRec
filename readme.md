# 背景

阿里妈妈反作弊业务中，有CPU上进行模型优化的需求。我们想请Intel的工程师帮忙优化其中一个模型，希望您能将分析、优化的过程详细记录下来，以便我们参考。对我们来说，优化方法比结果的一个数字更重要。
由于业务的敏感性，经过与业务团队讨论，我们无法直接将模型以及我们的代码分享出来。作为替代，我们选择了业务中一个重要而结构又普通的模型，它的结构与开源的YOLOv5几乎没有差别。因此，基于[YOLOv5](https://github.com/ultralytics/yolov5)的v5.0版本，选择yolov5m模型，我们将代码稍作修改，分享出来。


# 环境

我们目前线上部署的docker的硬件配置：CPU为skylake/icelake，skylake较多。容器一般申请20个core。skylake的内存为DDR4，实测内存总带宽有70GB/s和102GB/s两种配置。

docker文件单独给出，Dockerfile可供参考。

# 运行方法

首先下载开源的模型文件：
```
wget https://github.com/ultralytics/yolov5/releases/download/v4.0/yolov5m.pt
```
## 单独运行
可以参考ourmodel.py或demo.py
运行方法：
```
python3 ourmodel.py
```
## 运行服务
使用tornado启动web服务，并可以发压。我们实际的服务与这个类似。
```
sh run.sh
```
发压脚本：
```
python3 client.py --max=1000 --pool_size=20
```
输入的图片采用base64的方式传输给服务程序。由于后处理方法不同，没有经过后处理把结果返回，这对整体性能没有什么影响。模型计算的结果可供自行对比。


# 关于量化/精度

由于不能直接分享业务代码和模型，咱们无法比较方便地评估最终的精度效果。最终的效果需要我们业务方使用自己的测试集才能评估。不过这没有关系，低精度的方法如果在性能上有倍数的提升，即使精度上稍有下降，业务团队也会考虑。Intel这边只要给出性能数据和精度的数据即可，可以使用咱们常用的精度指标。

# 性能目标

我们的业务分为在线和离线。在线对RT要求较高，希望P99未来在200ms以内，因此目前多使用GPU，GPU不足的情况下也会使用CPU。离线对RT没要求，要求吞吐尽可能高，多使用CPU。
综上，希望咱们的优化方向以高吞吐为主。如果同时满足低延迟当然更好。我现在服务的配置中把opencv和pytorch的线程数设为1，这样能保证高吞吐，但由于只用了一个core，延迟就比较高，如果不这样设置则延迟低但吞吐也更低，这样设置的原因即如前所述。

当前代码的单机QPS为18,平均RT为约700ms。
